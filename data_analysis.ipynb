{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atd2020\n",
    "import numpy as np\n",
    "import math\n",
    "import multiprocessing  \n",
    "import random\n",
    "import pandas as pd\n",
    "import data_prep\n",
    "import read_data\n",
    "import modeling\n",
    "from functools import partial\n",
    "from sklearn.gaussian_process.kernels import (RBF,Matern,RationalQuadratic,ExpSineSquared,ConstantKernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing data file from /Users/qinghe/Documents/project/atd2021/atd2021/data/City4_all.parquet.brotli.\n"
     ]
    }
   ],
   "source": [
    "data, data_obs = read_data.load_in_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detrend the data to make it stationary (constant mean and variance)\n",
    "data_detrended = atd2020.detrend.detrend(data)\n",
    "groups_detrended = data_detrended.groupby([\"ID\", \"Weekday\", \"Hour\"])\n",
    "data_obs_detrended = atd2020.detrend.detrend(data_obs)\n",
    "groups_obs_detrended = data_obs_detrended.groupby([\"ID\", \"Weekday\", \"Hour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data first\n",
    "def standardize_self2(df, ycol=\"TotalFlow\"):\n",
    "    y = df[ycol]\n",
    "    m = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    df[\"TotalFlow_norm\"] = (y - m) / std\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ID_Hour_Wkdcat(data):\n",
    "    Weekdays_lst = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "    data_copy = data.copy()\n",
    "    data_copy[\"Weekday_cat\"] = np.where(data_copy.Weekday.isin(Weekdays_lst), 'wkd_c1', 'wkd_c2')\n",
    "    data_norm = data_copy.groupby([\"ID\",\"Weekday_cat\",\"Hour\"]).apply(standardize_self2)\n",
    "    data_norm.rename(\n",
    "        columns={\"TotalFlow\": \"TotalFlow_detrended\", \"TotalFlow_norm\": \"TotalFlow\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "    return data_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs_detrended_norm = normalize_ID_Hour_Wkdcat(data_obs_detrended)\n",
    "data_detrended_norm = normalize_ID_Hour_Wkdcat(data_detrended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the kernels\n",
    "kernels = [1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-1, 10.0)),\n",
    "           1.0* RationalQuadratic(length_scale=1.0,alpha=0.1,length_scale_bounds=(0.01, 10.0),alpha_bounds=(0.01, 10),),\n",
    "           1.0* ExpSineSquared(length_scale=1.0,periodicity=3.0,length_scale_bounds=(0.01, 100.0),periodicity_bounds=(1.0, 100.0),),\n",
    "            1.0 * Matern(length_scale=1.0, length_scale_bounds=(1e-1, 10.0), nu=1.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fraction_slice(fraction_groups, fraction):\n",
    "    fraction_groups_lst = list(fraction_groups.groups)\n",
    "    res = []\n",
    "    for i in fraction_groups_lst:\n",
    "        if i[3] == fraction:\n",
    "            res.append(i[0:3])\n",
    "    return res\n",
    "def train_val_test(seed, train_size, validation_size, slice_list):\n",
    "    # sample the training, validation, and test dataset\n",
    "    random.seed(seed)\n",
    "    training = random.sample(slice_list, train_size)\n",
    "    temp = [elem for elem in slice_list if not elem in training]\n",
    "    validation = random.sample(temp, validation_size)\n",
    "    # test = random.sample(temp2, test_size)\n",
    "    return training, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(data, data_obs, n_IDs, p_training, p_validation, kernel, cutoff):\n",
    "    random.seed(1234)\n",
    "    # random select IDs from 0 to 399\n",
    "    sampled_IDs = random.sample(range(400), n_IDs)\n",
    "    # print(sampled_IDs)\n",
    "    ################################################### Data prep ###################################################\n",
    "    # combine the data parallelly on IDs\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-3) # change the # of cpu here\n",
    "        temp = pool.map(partial(data_prep.data_prep_comb, data_obs_for_combine=data_obs, comb_hours=False, comb_wkd=True,hour_bef_aft=True),sampled_IDs)\n",
    "        pool.close()\n",
    "    # save the combined data as data_obs_new\n",
    "    data_obs_new = pd.DataFrame(columns=[\"ID\", \"Date\", \"Hour\", \"TotalFlow\"])\n",
    "    for i in temp:\n",
    "        data_obs_new = pd.concat([data_obs_new, i])\n",
    "    data_obs_new[\"Weekday\"] = [i.strftime(\"%A\") for i in data_obs_new.Date]\n",
    "\n",
    "    print(\"Data prep finished.\")\n",
    "    print(\"Peek the combined data:\")\n",
    "    print(data_obs_new.head())\n",
    "\n",
    "    ################################################### Training and validation ###################################################\n",
    "    # run the fraction-wise model parallelly on each fraction\n",
    "    fraction_ind = [0.01,0.02,0.05,0.1]\n",
    "    fraction_groups = data_obs[data_obs.ID.isin(sampled_IDs)].groupby(\n",
    "        [\"ID\", \"Weekday\", \"Hour\", \"Fraction_Observed\"]\n",
    "    )\n",
    "    training_lst=[]\n",
    "    validation_lst=[]\n",
    "    for fraction in fraction_ind:\n",
    "        slice_p = get_fraction_slice(fraction_groups, fraction)\n",
    "        training, validation = train_val_test(seed=123,train_size=math.floor(len(slice_p) * p_training),validation_size=math.floor(len(slice_p) * p_validation),\n",
    "        slice_list=slice_p)\n",
    "        training_lst.append(training)\n",
    "        validation_lst.append(validation)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-3) # change the # of cpu here\n",
    "        res_training = pool.map(partial(modeling.run_train_fraction, data=data, data_obs_new=data_obs_new, data_obs=data_obs, kernel=kernel,cutoff=cutoff),training_lst)\n",
    "        pool.close()\n",
    "    \n",
    "    iter_obj=[]\n",
    "    for i in range(4):\n",
    "        temp = []\n",
    "        temp.append(res_training[i])\n",
    "        temp.append(validation_lst[i])\n",
    "        iter_obj.append(temp)\n",
    "    # print(iter_obj)\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-3) # change the # of cpu here\n",
    "        res_validation = pool.map(partial(modeling.run_valid_fraction, data_obs_new=data_obs_new, data_obs=data_obs, kernel=kernel),iter_obj)\n",
    "        pool.close()\n",
    "    print(\"1% training f1:\", res_training[0]['training_F1'], \"1% validation f1:\", res_validation[0]['validation_F1'])\n",
    "    print(\"2% training f1:\", res_training[1]['training_F1'], \"2% validation f1:\", res_validation[1]['validation_F1'])\n",
    "    print(\"5% training f1:\", res_training[2]['training_F1'], \"5% validation f1:\", res_validation[2]['validation_F1'])\n",
    "    print(\"10% training f1:\", res_training[3]['training_F1'], \"10% validation f1:\", res_validation[3]['validation_F1'])\n",
    "    # return the models and F1 scores\n",
    "    return (iter_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model on the detrended normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prep finished.\n",
      "Peek the combined data:\n",
      "    ID        Date Hour  TotalFlow    Weekday\n",
      "0  265  2011-01-03   22   -1.56472     Monday\n",
      "1  265  2011-01-05   22   -1.56472  Wednesday\n",
      "2  265  2011-01-06   22   -1.56472   Thursday\n",
      "3  265  2011-01-07   22   -1.56472     Friday\n",
      "4  265  2011-01-04   21   -1.56472    Tuesday\n",
      "1% training f1: 0.5913621262458473 1% validation f1: 0.6106870229007634\n",
      "2% training f1: 0.6823266219239374 2% validation f1: 0.6932835820895523\n",
      "5% training f1: 0.758674585808065 5% validation f1: 0.7574233327924712\n",
      "10% training f1: 0.822360248447205 10% validation f1: 0.8267756770567194\n"
     ]
    }
   ],
   "source": [
    "data_detrended_norm_clean = data_detrended_norm.drop(['Year', 'Month','Day','Latitude','Longitude','Weekday_cat'], axis=1)\n",
    "data_obs_detrended_norm_clean = data_obs_detrended_norm.drop(['Year', 'Month','Day','Latitude','Longitude','Weekday_cat'], axis=1)\n",
    "result = final_model(data=data_detrended_norm_clean, data_obs=data_obs_detrended_norm_clean, n_IDs=400, p_training=0.5, p_validation=0.5,\n",
    "kernel=kernels[1], cutoff=[x / 100.0 for x in range(10, 100, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"/Users/qinghe/Documents/project/atd2021/results/sprint4/result.pkl\", \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "# random select IDs from 0 to 399\n",
    "sampled_IDs = random.sample(range(400), 200)\n",
    "validation_IDs = [i for i in range(400) if i not in sampled_IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>TotalFlow_original</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Fraction_Observed</th>\n",
       "      <th>Observed</th>\n",
       "      <th>Date</th>\n",
       "      <th>TotalFlow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87646</th>\n",
       "      <td>2011-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1682.995664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87714</th>\n",
       "      <td>2011-01-04 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>496.753393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87772</th>\n",
       "      <td>2011-01-06 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>4543.546751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87988</th>\n",
       "      <td>2011-01-15 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-15</td>\n",
       "      <td>4857.777185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88083</th>\n",
       "      <td>2011-01-19 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3441.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>3591.438719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  ID  TotalFlow_original  Year  Month  Day  Hour  \\\n",
       "87646 2011-01-01 08:00:00   1              1531.0  2011      1    1     8   \n",
       "87714 2011-01-04 04:00:00   1               345.0  2011      1    4     4   \n",
       "87772 2011-01-06 14:00:00   1              4392.0  2011      1    6    14   \n",
       "87988 2011-01-15 14:00:00   1              4707.0  2011      1   15    14   \n",
       "88083 2011-01-19 13:00:00   1              3441.0  2011      1   19    13   \n",
       "\n",
       "         Weekday  Latitude  Longitude  Anomaly  Fraction_Observed  Observed  \\\n",
       "87646   Saturday  0.510311   0.836739    False               0.02      True   \n",
       "87714    Tuesday  0.510311   0.836739    False               0.02      True   \n",
       "87772   Thursday  0.510311   0.836739    False               0.02      True   \n",
       "87988   Saturday  0.510311   0.836739    False               0.02      True   \n",
       "88083  Wednesday  0.510311   0.836739    False               0.02      True   \n",
       "\n",
       "             Date    TotalFlow  \n",
       "87646  2011-01-01  1682.995664  \n",
       "87714  2011-01-04   496.753393  \n",
       "87772  2011-01-06  4543.546751  \n",
       "87988  2011-01-15  4857.777185  \n",
       "88083  2011-01-19  3591.438719  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_detrended = data_obs_detrended[data_obs_detrended.ID.isin(validation_IDs)].copy()\n",
    "validation_detrended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ID</th>\n",
       "      <th>TotalFlow_original</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Fraction_Observed</th>\n",
       "      <th>Observed</th>\n",
       "      <th>Date</th>\n",
       "      <th>TotalFlow</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>lower_thresh</th>\n",
       "      <th>upper_thresh</th>\n",
       "      <th>Fallback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1682.995664</td>\n",
       "      <td>2940.146196</td>\n",
       "      <td>674.180771</td>\n",
       "      <td>17</td>\n",
       "      <td>917.603882</td>\n",
       "      <td>4962.688510</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-04 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>496.753393</td>\n",
       "      <td>726.139492</td>\n",
       "      <td>330.526472</td>\n",
       "      <td>19</td>\n",
       "      <td>-265.439923</td>\n",
       "      <td>1717.718908</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-06 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>4543.546751</td>\n",
       "      <td>4085.400645</td>\n",
       "      <td>414.486975</td>\n",
       "      <td>10</td>\n",
       "      <td>2841.939721</td>\n",
       "      <td>5328.861569</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-15 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-15</td>\n",
       "      <td>4857.777185</td>\n",
       "      <td>4446.508129</td>\n",
       "      <td>282.681089</td>\n",
       "      <td>11</td>\n",
       "      <td>3598.464860</td>\n",
       "      <td>5294.551397</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-19 13:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3441.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.510311</td>\n",
       "      <td>0.836739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>3591.438719</td>\n",
       "      <td>3869.423685</td>\n",
       "      <td>404.793823</td>\n",
       "      <td>11</td>\n",
       "      <td>2655.042217</td>\n",
       "      <td>5083.805153</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  ID  TotalFlow_original  Year  Month  Day  Hour  \\\n",
       "0 2011-01-01 08:00:00   1              1531.0  2011      1    1     8   \n",
       "1 2011-01-04 04:00:00   1               345.0  2011      1    4     4   \n",
       "2 2011-01-06 14:00:00   1              4392.0  2011      1    6    14   \n",
       "3 2011-01-15 14:00:00   1              4707.0  2011      1   15    14   \n",
       "4 2011-01-19 13:00:00   1              3441.0  2011      1   19    13   \n",
       "\n",
       "     Weekday  Latitude  Longitude  ...  Fraction_Observed  Observed  \\\n",
       "0   Saturday  0.510311   0.836739  ...               0.02      True   \n",
       "1    Tuesday  0.510311   0.836739  ...               0.02      True   \n",
       "2   Thursday  0.510311   0.836739  ...               0.02      True   \n",
       "3   Saturday  0.510311   0.836739  ...               0.02      True   \n",
       "4  Wednesday  0.510311   0.836739  ...               0.02      True   \n",
       "\n",
       "         Date    TotalFlow         mean         std  count  lower_thresh  \\\n",
       "0  2011-01-01  1682.995664  2940.146196  674.180771     17    917.603882   \n",
       "1  2011-01-04   496.753393   726.139492  330.526472     19   -265.439923   \n",
       "2  2011-01-06  4543.546751  4085.400645  414.486975     10   2841.939721   \n",
       "3  2011-01-15  4857.777185  4446.508129  282.681089     11   3598.464860   \n",
       "4  2011-01-19  3591.438719  3869.423685  404.793823     11   2655.042217   \n",
       "\n",
       "   upper_thresh  Fallback  \n",
       "0   4962.688510     False  \n",
       "1   1717.718908     False  \n",
       "2   5328.861569     False  \n",
       "3   5294.551397     False  \n",
       "4   5083.805153     False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_detrended.reset_index(drop=True, inplace=True)\n",
    "# Returns a dataframe with predicted anomalies in the 'Anomaly' column\n",
    "anomalies_baseline = atd2020.detector.BaselineDetector().fit_predict(validation_detrended)\n",
    "anomalies_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Positive</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraction_Observed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>6054</td>\n",
       "      <td>2065</td>\n",
       "      <td>767349</td>\n",
       "      <td>4567</td>\n",
       "      <td>0.745658</td>\n",
       "      <td>0.570003</td>\n",
       "      <td>0.646105</td>\n",
       "      <td>0.991498</td>\n",
       "      <td>10621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41584</td>\n",
       "      <td>510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987837</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>149</td>\n",
       "      <td>69</td>\n",
       "      <td>88070</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.683486</td>\n",
       "      <td>0.11788</td>\n",
       "      <td>0.20108</td>\n",
       "      <td>0.986757</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05</th>\n",
       "      <td>1768</td>\n",
       "      <td>834</td>\n",
       "      <td>232579</td>\n",
       "      <td>1447</td>\n",
       "      <td>0.679477</td>\n",
       "      <td>0.549922</td>\n",
       "      <td>0.607873</td>\n",
       "      <td>0.99036</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>4137</td>\n",
       "      <td>1160</td>\n",
       "      <td>405116</td>\n",
       "      <td>1495</td>\n",
       "      <td>0.781008</td>\n",
       "      <td>0.734553</td>\n",
       "      <td>0.757068</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>5632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   True Positive  False Positive  True Negative  \\\n",
       "Fraction_Observed                                                 \n",
       "overall                     6054            2065         767349   \n",
       "0.01                           0               2          41584   \n",
       "0.02                         149              69          88070   \n",
       "0.05                        1768             834         232579   \n",
       "0.1                         4137            1160         405116   \n",
       "\n",
       "                   False Negative  Precision    Recall        F1  Accuracy  \\\n",
       "Fraction_Observed                                                            \n",
       "overall                      4567   0.745658  0.570003  0.646105  0.991498   \n",
       "0.01                          510        0.0       0.0       0.0  0.987837   \n",
       "0.02                         1115   0.683486   0.11788   0.20108  0.986757   \n",
       "0.05                         1447   0.679477  0.549922  0.607873   0.99036   \n",
       "0.1                          1495   0.781008  0.734553  0.757068  0.993554   \n",
       "\n",
       "                   Support  \n",
       "Fraction_Observed           \n",
       "overall              10621  \n",
       "0.01                   510  \n",
       "0.02                  1264  \n",
       "0.05                  3215  \n",
       "0.1                   5632  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_baseline = atd2020.metrics.metrics(\n",
    "    validation_detrended,\n",
    "    anomalies_baseline,\n",
    "    groupby=\"Fraction_Observed\",\n",
    ")\n",
    "metrics_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling_GBM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBM1(data, data_obs, n_IDs, p_training, p_validation, kernel):\n",
    "    random.seed(1234)\n",
    "    # random select IDs from 0 to 399\n",
    "    sampled_IDs = random.sample(range(400), n_IDs)\n",
    "    # print(sampled_IDs)\n",
    "    ################################################### Data prep ###################################################\n",
    "    # combine the data parallelly on IDs\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-3) # change the # of cpu here\n",
    "        temp = pool.map(partial(data_prep.data_prep_comb, data_obs_for_combine=data_obs, comb_hours=False, comb_wkd=True,hour_bef_aft=True),sampled_IDs)\n",
    "        pool.close()\n",
    "    # save the combined data as data_obs_new\n",
    "    data_obs_new = pd.DataFrame(columns=[\"ID\", \"Date\", \"Hour\", \"TotalFlow\"])\n",
    "    for i in temp:\n",
    "        data_obs_new = pd.concat([data_obs_new, i])\n",
    "    data_obs_new[\"Weekday\"] = [i.strftime(\"%A\") for i in data_obs_new.Date]\n",
    "\n",
    "    print(\"Data prep finished.\")\n",
    "    print(\"Peek the combined data:\")\n",
    "    print(data_obs_new.head())\n",
    "\n",
    "    ################################################### Training and validation ###################################################\n",
    "    # run the fraction-wise model parallelly on each fraction\n",
    "    fraction_ind = [0.01,0.02,0.05,0.1]\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-4) # change the # of cpu here\n",
    "        res = pool.map(partial(modeling_GBM2.run_train_fraction2, data=data, data_obs_new=data_obs_new, data_obs=data_obs, kernel=kernel, \n",
    "                                sampled_IDs=sampled_IDs, p_training=p_training, p_validation=p_validation),fraction_ind)\n",
    "        pool.close()\n",
    "    print(\"1% training f1:\", res[0]['training_F1'], \"1% validation f1:\", res[0]['validation_F1'])\n",
    "    print(\"2% training f1:\", res[1]['training_F1'], \"2% validation f1:\", res[1]['validation_F1'])\n",
    "    print(\"5% training f1:\", res[2]['training_F1'], \"5% validation f1:\", res[2]['validation_F1'])\n",
    "    print(\"10% training f1:\", res[3]['training_F1'], \"10% validation f1:\", res[3]['validation_F1'])\n",
    "    # return the models and F1 scores\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_detrended_norm_clean = data_detrended_norm.drop(['Year', 'Month','Day','Latitude','Longitude','Weekday_cat'], axis=1)\n",
    "data_obs_detrended_norm_clean = data_obs_detrended_norm.drop(['Year', 'Month','Day','Latitude','Longitude','Weekday_cat'], axis=1)\n",
    "result = GBM1(data=data_detrended_norm_clean, data_obs=data_obs_detrended_norm_clean, n_IDs=400, p_training=0.5, p_validation=0.5,\n",
    "kernel=kernels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling_GBM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GBM2(data, data_obs, n_IDs, p_training, p_validation, kernel):\n",
    "    random.seed(1234)\n",
    "    # random select IDs from 0 to 399\n",
    "    sampled_IDs = random.sample(range(400), n_IDs)\n",
    "    # print(sampled_IDs)\n",
    "    ################################################### Data prep ###################################################\n",
    "    # combine the data parallelly on IDs\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-3) # change the # of cpu here\n",
    "        temp = pool.map(partial(data_prep.data_prep_comb, data_obs_for_combine=data_obs, comb_hours=False, comb_wkd=True,hour_bef_aft=True),sampled_IDs)\n",
    "        pool.close()\n",
    "    # save the combined data as data_obs_new\n",
    "    data_obs_new = pd.DataFrame(columns=[\"ID\", \"Date\", \"Hour\", \"TotalFlow\"])\n",
    "    for i in temp:\n",
    "        data_obs_new = pd.concat([data_obs_new, i])\n",
    "    data_obs_new[\"Weekday\"] = [i.strftime(\"%A\") for i in data_obs_new.Date]\n",
    "\n",
    "    print(\"Data prep finished.\")\n",
    "    print(\"Peek the combined data:\")\n",
    "    print(data_obs_new.head())\n",
    "\n",
    "    ################################################### Training and validation ###################################################\n",
    "    # run the fraction-wise model parallelly on each fraction\n",
    "    fraction_ind = [0.01,0.02,0.05,0.1]\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-4) # change the # of cpu here\n",
    "        res = pool.map(partial(modeling_GBM1.run_train_fraction2, data=data, data_obs_new=data_obs_new, data_obs=data_obs, kernel=kernel, \n",
    "                                sampled_IDs=sampled_IDs, p_training=p_training, p_validation=p_validation),fraction_ind)\n",
    "        pool.close()\n",
    "    print(\"1% training f1:\", res[0]['training_F1'], \"1% validation f1:\", res[0]['validation_F1'])\n",
    "    print(\"2% training f1:\", res[1]['training_F1'], \"2% validation f1:\", res[1]['validation_F1'])\n",
    "    print(\"5% training f1:\", res[2]['training_F1'], \"5% validation f1:\", res[2]['validation_F1'])\n",
    "    print(\"10% training f1:\", res[3]['training_F1'], \"10% validation f1:\", res[3]['validation_F1'])\n",
    "    # return the models and F1 scores\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_detrended_norm_clean = data_detrended_norm.drop(['Year', 'Month','Day','Latitude','Longitude','Weekday_cat'], axis=1)\n",
    "data_obs_detrended_norm_clean = data_obs_detrended_norm.drop(['Year', 'Month','Day','Latitude','Longitude','Weekday_cat'], axis=1)\n",
    "result = GBM2(data=data_detrended_norm_clean, data_obs=data_obs_detrended_norm_clean, n_IDs=400, p_training=0.5, p_validation=0.5,\n",
    "kernel=kernels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdaaf489275c69da8886cebf22a66d2db93e1b1656bb95630599b16c4d98f331"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "330b2fe339b5428d468ab024b52eb28c44d340adc4e8984408160247b6ffa196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
